{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "from uuid import uuid4\n",
    "from pydantic import ValidationError\n",
    "from typing import Literal\n",
    "import logging\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain_community.chat_message_histories import RedisChatMessageHistory\n",
    "from langchain_core.messages import BaseMessage, AIMessage, HumanMessage, get_buffer_string\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "from langchain_core.tracers.langchain import LangChainTracer\n",
    "from langsmith.client import Client\n",
    "from langchain_core.tracers.context import tracing_v2_callback_var\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Sequence, TypedDict\n",
    "from langchain_core.messages import BaseMessage\n",
    "import operator\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    chat_history: list[BaseMessage]\n",
    "    chain: str\n",
    "    team_members: list[str]\n",
    "    tool_results: dict[str, dict]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"agent\", self._call_model)\n",
    "workflow.add_node(\"tools\", ToolNode(self.tools))\n",
    "\n",
    "workflow.add_edge(START, \"agent\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    self._should_continue,\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "return await workflow.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_workflow(self):\n",
    "    \"\"\"Get the workflow for the conversation.\"\"\"\n",
    "\n",
    "    workflow = StateGraph(AgentState)\n",
    "\n",
    "    workflow.add_node(\"topic_validator\", self._topic_validation)\n",
    "\n",
    "    workflow.add_node(\"supervisor\", self.get_supervisor())\n",
    "\n",
    "    workflow.add_node(\"exception_node\", self._answer_chain)\n",
    "\n",
    "    supervisor_conditional_edges = {}\n",
    "    for agent in self.config.agents.keys():\n",
    "        workflow.add_node(agent, self._run_agent)\n",
    "        supervisor_conditional_edges[agent] = agent\n",
    "    supervisor_conditional_edges[\"FINISH\"] = END\n",
    "\n",
    "    workflow.add_node(\"answer_chain\", self._answer_chain)\n",
    "\n",
    "    workflow.set_entry_point(\"topic_validator\")\n",
    "    workflow.add_conditional_edges(\n",
    "        \"topic_validator\",\n",
    "        self._should_continue_exception\n",
    "    )\n",
    "\n",
    "    workflow.add_edge(\"exception_node\", END)\n",
    "\n",
    "    workflow.add_conditional_edges(\n",
    "        \"supervisor\",\n",
    "        lambda x: x[\"chain\"],\n",
    "        supervisor_conditional_edges\n",
    "    )\n",
    "\n",
    "    for agent in self.config.agents.keys():\n",
    "        if \"rag_call_tool\" in self.config.agents[agent].tools.keys():\n",
    "            workflow.add_edge(agent, END)\n",
    "        else:\n",
    "            workflow.add_conditional_edges(\n",
    "                agent,\n",
    "                self._should_continue\n",
    "            )\n",
    "    workflow.add_edge(\"answer_chain\", END)\n",
    "    # workflow.add_edge(\"answer_chain\", \"supervisor\")\n",
    "\n",
    "    graph = workflow.compile(debug=self.config.debug)\n",
    "\n",
    "    # Save the graph image if debug_graph is enabled\n",
    "    if self.config.debug_graph:\n",
    "        try:\n",
    "            graph_image = graph.get_graph(xray=True).draw_mermaid_png()\n",
    "            with open('graph.png', 'wb') as f:\n",
    "                f.write(graph_image)\n",
    "\n",
    "        except Exception as ex:\n",
    "            logging.getLogger(\"uvicorn\").error(\n",
    "                \"Error while displaying the graph: \" + str(ex))\n",
    "\n",
    "    return graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
